{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surya\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the final train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.read_csv('final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the final test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test=pd.read_csv('final_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the type as category for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[\"city\"] = final[\"city\"].astype(\"category\")\n",
    "final[\"registered_via\"] = final[\"registered_via\"].astype(\"category\")\n",
    "final[\"registration_init_time_year\"] = final[\"registration_init_time_year\"].astype(\"category\")\n",
    "final[\"registration_init_time_month\"] = final[\"registration_init_time_month\"].astype(\"category\")\n",
    "final[\"registration_init_time_day\"] = final[\"registration_init_time_day\"].astype(\"category\")\n",
    "final[\"payment_method_id\"] = final[\"payment_method_id\"].astype(\"category\")\n",
    "final[\"payment_plan_days\"] = final[\"payment_plan_days\"].astype(\"category\")\n",
    "final[\"is_cancel\"] = final[\"is_cancel\"].astype(\"category\")\n",
    "final[\"is_auto_renew\"] = final[\"is_auto_renew\"].astype(\"category\")\n",
    "final[\"transaction_date_year\"] = final[\"transaction_date_year\"].astype(\"category\")\n",
    "final[\"transaction_date_month\"] = final[\"transaction_date_month\"].astype(\"category\")\n",
    "final[\"transaction_date_day\"] = final[\"transaction_date_day\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test[\"city\"] = final_test[\"city\"].astype(\"category\")\n",
    "#final_test[\"registered_via\"] = final_test[\"registered_via\"].astype(\"category\")\n",
    "#final_test[\"registration_init_time_year\"] = final_test[\"registration_init_time_year\"].astype(\"category\")\n",
    "#final_test[\"registration_init_time_month\"] = final_test[\"registration_init_time_month\"].astype(\"category\")\n",
    "#final_test[\"registration_init_time_day\"] = final_test[\"registration_init_time_day\"].astype(\"category\")\n",
    "#final_test[\"payment_method_id\"] = final_test[\"payment_method_id\"].astype(\"category\")\n",
    "#final_test[\"payment_plan_days\"] = final_test[\"payment_plan_days\"].astype(\"category\")\n",
    "#final_test[\"is_cancel\"] = final_test[\"is_cancel\"].astype(\"category\")\n",
    "#final_test[\"is_auto_renew\"] = final_test[\"is_auto_renew\"].astype(\"category\")\n",
    "#final_test[\"transaction_date_year\"] = final_test[\"transaction_date_year\"].astype(\"category\")\n",
    "#final_test[\"transaction_date_month\"] = final_test[\"transaction_date_month\"].astype(\"category\")\n",
    "#final_test[\"transaction_date_day\"] = final_test[\"transaction_date_day\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = final['is_churn'].values\n",
    "final.drop(['is_churn','msno'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time_year</th>\n",
       "      <th>registration_init_time_month</th>\n",
       "      <th>registration_init_time_day</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>...</th>\n",
       "      <th>transaction_date_month</th>\n",
       "      <th>transaction_date_day</th>\n",
       "      <th>logs_count</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>11.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>80598.557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  registered_via  registration_init_time_year  \\\n",
       "0   5.0             3.0                         2013   \n",
       "\n",
       "   registration_init_time_month  registration_init_time_day  \\\n",
       "0                            12                          23   \n",
       "\n",
       "   payment_method_id  payment_plan_days  plan_list_price  actual_amount_paid  \\\n",
       "0                 38                 30              149                 149   \n",
       "\n",
       "   is_cancel     ...      transaction_date_month  transaction_date_day  \\\n",
       "0          0     ...                           2                    28   \n",
       "\n",
       "   logs_count  num_25  num_50  num_75  num_985  num_100  num_unq  total_secs  \n",
       "0        11.0   186.0    23.0    13.0     10.0    318.0    348.0   80598.557  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = final\n",
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train)\n",
    "X_train, X_cv, Y_train, Y_cv = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(482900, 29) (482900,)\n",
      "(150907, 29) (150907,)\n",
      "(120725, 29) (120725,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)\n",
    "print(X_cv.shape, Y_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying StandardScaler on numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['plan_list_price', 'actual_amount_paid','trans_count','transaction_span','total_list_price','total_amount_paid','is_cancel_sum','difference_in_price_paid','amount_paid_perday','logs_count','num_25','num_50','num_75','num_985','num_100','num_unq','total_secs']] = scaler.fit_transform(X_train[['plan_list_price', 'actual_amount_paid','trans_count','transaction_span','total_list_price','total_amount_paid','is_cancel_sum','difference_in_price_paid','amount_paid_perday','logs_count','num_25','num_50','num_75','num_985','num_100','num_unq','total_secs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['plan_list_price', 'actual_amount_paid','trans_count','transaction_span','total_list_price','total_amount_paid','is_cancel_sum','difference_in_price_paid','amount_paid_perday','logs_count','num_25','num_50','num_75','num_985','num_100','num_unq','total_secs']] = scaler.transform(X_test[['plan_list_price', 'actual_amount_paid','trans_count','transaction_span','total_list_price','total_amount_paid','is_cancel_sum','difference_in_price_paid','amount_paid_perday','logs_count','num_25','num_50','num_75','num_985','num_100','num_unq','total_secs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv[['plan_list_price', 'actual_amount_paid','trans_count','transaction_span','total_list_price','total_amount_paid','is_cancel_sum','difference_in_price_paid','amount_paid_perday','logs_count','num_25','num_50','num_75','num_985','num_100','num_unq','total_secs']] = scaler.transform(X_cv[['plan_list_price', 'actual_amount_paid','trans_count','transaction_span','total_list_price','total_amount_paid','is_cancel_sum','difference_in_price_paid','amount_paid_perday','logs_count','num_25','num_50','num_75','num_985','num_100','num_unq','total_secs']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(X,Y):\n",
    "    \"\"\"This function is used to get the input X,Y and it gives the log loss and accuracy score based on LGBMClassifier.\"\"\"\n",
    "    \n",
    "    x_cfl=LGBMClassifier(objective ='binary', eval_metric = 'logloss',class_weight='balanced',subsample=0.3,num_leaves =1500,\n",
    "                    n_estimators=1000,max_depth=5,learning_rate=0.2,colsample_bytree=0.5,feature_fraction=0.2)\n",
    "    x_cfl.fit(X,Y)\n",
    "    c_cfl=CalibratedClassifierCV(x_cfl,method='sigmoid')\n",
    "    c_cfl.fit(X,Y)\n",
    "    \n",
    "    predict_y = c_cfl.predict_proba(X)\n",
    "    print ('log loss is',log_loss(Y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss is 0.08499339948285352\n"
     ]
    }
   ],
   "source": [
    "train_metric = final_model(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss is 0.0533228009097414\n"
     ]
    }
   ],
   "source": [
    "cv_metric = final_model(X_cv,Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss is 0.05831275557349452\n"
     ]
    }
   ],
   "source": [
    "test_metric = final_model(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing categorical feature type as category gives better result than the LGM model in the \"Data modelling and ML Models notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imported all the data's and joined into a single dataframe based on msno.\n",
    "\n",
    "2. With EDA found out the features to be used and not to be used, created new features based on the given features.\n",
    "\n",
    "3. Seperated features into Categorical and Numerical features\n",
    "\n",
    "4. For Categorical features did one hot encoding and for numerical features did standard scalar.\n",
    "\n",
    "5. Tried Logistic regression ,SVM and LightGBM models, Light GBM model with class balance gives the result.\n",
    "\n",
    "6. In the final notebook implemeted the LightGBM model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
